{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model I/O\n",
    "![](https://python.langchain.com/assets/images/model_io-e6fc0045b7eae0377a4ddeb90dc8cdb8.jpg)\n",
    "[Model I/O](https://python.langchain.com/docs/modules/model_io/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM returns a string\n",
    "\n",
    "from langchain_community.llms import Ollama\n",
    "\n",
    "llm=Ollama(model=\"llama2\")\n",
    "text=\"Tell me a joke\"\n",
    "\n",
    "llm.invoke(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Sure! Here's one:\\n\\nWhy don't scientists trust atoms?\\nBecause they make up everything!\\n\\nI hope that brought a smile to your face!\", response_metadata={'model': 'llama2', 'created_at': '2024-04-29T06:32:36.35505Z', 'message': {'role': 'assistant', 'content': ''}, 'done': True, 'total_duration': 3157366042, 'load_duration': 12627000, 'prompt_eval_duration': 1250964000, 'eval_count': 40, 'eval_duration': 1885521000}, id='run-2aa62a76-0e5a-416b-bce8-5d47ab90313a-0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ChateModel returns a message\n",
    "\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "chat_model=ChatOllama()\n",
    "text=\"Tell me a joke\"\n",
    "messages=[HumanMessage(content=text)]\n",
    "\n",
    "chat_model.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "China is located on the Asian continent.\n",
      "\n",
      "The United States of America (USA) is located on the continent of North America.\n",
      "France is located on the continent of Europe.\n"
     ]
    }
   ],
   "source": [
    "# Use PromptTemplate in LLM\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_community.llms import Ollama\n",
    "\n",
    "prompt=PromptTemplate.from_template(\"What continent is {country} located on?\")\n",
    "\n",
    "llm=Ollama(model=\"llama2\")\n",
    "for country in ['China','USA','France']:\n",
    "    print(llm.invoke(prompt.format(country=country)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Buenas noches! (Good evening!)', response_metadata={'model': 'llama2', 'created_at': '2024-04-29T06:57:43.563079Z', 'message': {'role': 'assistant', 'content': ''}, 'done': True, 'total_duration': 4922741625, 'load_duration': 4263701792, 'prompt_eval_count': 32, 'prompt_eval_duration': 211350000, 'eval_count': 10, 'eval_duration': 438753000}, id='run-df1525e0-cbe9-42fa-ac4d-ba827054cf72-0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use ChatPromptTemplate in ChatModel\n",
    "\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.prompts.chat import ChatPromptTemplate\n",
    "\n",
    "system_template=\"You are a translator from {input_language} to {output_language}\"\n",
    "human_template=\"{text}\"\n",
    "\n",
    "chat_prompt=ChatPromptTemplate.from_messages([\n",
    "    (\"system\",system_template),\n",
    "    (\"human\",human_template),\n",
    "])\n",
    "\n",
    "chat_model=ChatOllama()\n",
    "chat_model.invoke(chat_prompt.format_messages(\n",
    "    input_language=\"English\",\n",
    "    output_language=\"Spanish\",\n",
    "    text=\"Good evening!\"\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sure! Here is a sample text separated by commas:\\n\\nThe cat purred contentedly on my lap', 'the sun shone brightly overhead', 'and I sipped a cold glass of lemonade while reading a good book.']\n"
     ]
    }
   ],
   "source": [
    "# Split by comma\n",
    "\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "\n",
    "output_parser=CommaSeparatedListOutputParser()\n",
    "\n",
    "llm=Ollama(model=\"llama2\")\n",
    "text=\"Give me a sample text, separated by commas\"\n",
    "\n",
    "print(output_parser.parse(llm.invoke(text)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Of course! Here are ten different fruits:\\n\\n1. Apple\\n2. Banana\\n3. Orange\\n4. Mango\\n5. Watermelon\\n6. Grapes\\n7. Strawberry\\n8. Pineapple\\n9. Kiwi\\n10. Blueberry' response_metadata={'model': 'llama2', 'created_at': '2024-04-29T07:26:55.961608Z', 'message': {'role': 'assistant', 'content': ''}, 'done': True, 'total_duration': 6636492542, 'load_duration': 10198958, 'prompt_eval_duration': 3026638000, 'eval_count': 66, 'eval_duration': 3596124000} id='run-baadc586-0260-4eed-aab4-0618cb338120-0'\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "human_template=\"Generate a list of {number} {item}s\"\n",
    "\n",
    "chat_model=ChatOllama()\n",
    "chat_prompt=ChatPromptTemplate.from_template(human_template)\n",
    "output_parser=StrOutputParser()\n",
    "\n",
    "print(output_parser.parse(chat_model.invoke(chat_prompt.format(number=\"10\",item=\"fruit\"))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
